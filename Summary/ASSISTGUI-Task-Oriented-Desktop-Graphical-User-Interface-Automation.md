# ASSISTGUI: Task-Oriented Desktop Graphical User Interface Automation

## 思维导图
![思维导图](/imgs/ASSISTGUI-Task-Oriented-Desktop-Graphical-User-Interface-Automation.jpg)

## 全文总结
“ASSISTGUI: Task-Oriented Desktop Graphical User Interface Automation” 由 Difei Gao 等人撰写，主要介绍了用于评估模型在 Windows 平台上执行任务能力的 ASSISTGUI 基准，以及相关的实验和分析。
### 1.研究背景
#### GUI 自动化的重要性：
图形用户界面（GUI）自动化有望帮助用户完成复杂任务，提高生产力。现有的基于大语言模型（LLM）或 LLM 代理的工作主要集中在简单设备使用和娱乐操作上，而针对生产力软件的任务自动化研究较少。
#### 任务挑战：
桌面任务自动化面临密集的 GUI 理解、复杂操作和长流程等挑战，需要模型能够理解各种视觉元素，执行复杂动作，并处理一系列步骤。
### 2.ASSISTGUI 基准
#### 任务制定：
包括任务描述（自然语言查询和补充视频）、状态观察（操作系统元数据和屏幕截图）和动作空间（鼠标和键盘操作）。
#### 数据收集：
涵盖设计、办公、系统设置、小部件使用和文件管理等五大类任务，从 9 个常用应用程序中收集了 100 个特定任务，每个任务都有文本查询、教学视频和项目文件。
#### 评估方法：
采用结果导向的评估方法，根据不同任务类型（设计、办公、小部件、系统设置、文件管理）设计特定指标计算成功率。
### 3.方法介绍
#### ACE 框架：
基于 LLMs 的 Actor-Critic Embodied Agent 框架，包括规划器、GUI 解析器、评估器和执行器四个模块。规划器创建任务树，GUI 解析器将屏幕截图转换为结构化文本，评估器评估执行动作的成功与否，执行器根据反馈生成动作。
#### 模块功能
##### 规划器：
根据查询和视频生成分层任务树，包括里程碑和子任务。
##### GUI 解析器：
利用多种工具提取 UI 元素信息，将截图转换为结构化文本。
##### 评估器：
通过分析前后截图评估动作执行效果，输出成功标志、完成标志和解释。
##### 执行器：
根据评估器反馈生成动作，考虑多种因素，如当前状态、历史动作等。
### 4.实验结果
#### 定量结果
##### 与 SOTA 规划方法比较：
提出的方法在 ASSISTGUI 基准上显著优于 CoT 和 ReAct 等现有规划方法。
##### GUI 解析器消融实验：
OCR 和图标对性能影响较大，面板布局影响较小。
##### 大语言模型影响：
GPT-4 表现较好，其他模型因输出格式和模型幻觉等问题效果不佳。
#### 定性结果：
展示了成功预测案例、常见错误（如复杂操作、模糊区域理解、文本空间关系处理）、规划器预测示例、GUI 解析器输出示例和 Actor 与 Critic 模块预测示例。
### 5.与先前基准的比较：
ASSISTGUI 专注于桌面操作和生产力工具的使用，与主要关注 Web 和智能手机平台、游戏或简单操作的先前基准不同，且提供项目文件确保公平比较。
### 6.研究结论：
提出了 ASSISTGUI 基准和 Actor-Critic Embodied Agent 框架，实验结果显示方法有优势，但仍面临挑战，未来需改进 GUI 理解和动作生成能力。
