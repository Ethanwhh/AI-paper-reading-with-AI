# ScreenAI: A Vision-Language Model for UI and Infographics Understanding

## 思维导图
![思维导图](/imgs/ScreenAI-A-Vision-Language-Model-for-UI-and-Infographics-Understanding.jpg)

## 全文总结

“ScreenAI: A Vision-Language Model for UI and Infographics Understanding” 介绍了 ScreenAI 模型，它专注于用户界面（UI）和信息图表理解，在多个相关任务上取得优异成果，并发布新数据集推动该领域研究。

### 1.研究背景与相关工作

- 背景：信息图表和 UI 在人机交互等方面作用关键，但因其复杂性，构建能理解和处理它们的统一模型颇具挑战。

- 相关工作分类：屏幕基础 UI 模型，如检测图标或 UI 元素等任务；通用基础模型，在多模态领域处理图像理解任务；高效视觉语言模型，解决文档理解等任务。本文模型在预训练任务和数据生成上有创新，性能更优。

### 2.ScreenAI 模型方法

- 架构：受 PaLI 模型启发，由多模态编码器（含 ViT 视觉编码器和 mT5 语言编码器）和自回归解码器组成，扩展接受多种图像补丁模式（借鉴 Pix2Struct），适应不同分辨率和纵横比图像。

- 模型配置：训练 3 种大小（670M、2B、5B 参数）模型，从不同预训练检查点开始，各模型的视觉和语言模型参数分布不同，且有不同的输入分辨率和序列长度预算。

- 训练阶段：预训练从特定检查点开始，用自监督和其他模型生成的大数据集训练视觉编码器和语言模型，后期冻结 ViT 编码器；微调针对不同任务或任务组合在标注数据上进行。

### 3.自动数据生成

- 屏幕标注：收集多设备截图，用基于 DETR 的布局标注器、图标分类器、OCR 引擎等标注 UI 元素、空间关系和文本内容，创建包含元素名称、OCR 文本等的屏幕模式，作为预训练任务和与大语言模型交互的工具。

- 利用大语言模型生成任务：基于屏幕模式用 PaLM 2 - S 等生成问答对、导航指令、总结等任务，经人工验证保证数据质量，丰富预训练数据多样性。

### 4.数据混合

- 预训练任务：包括屏幕标注（检测识别 UI 元素、OCR 和图像字幕等）、屏幕问答（针对界面和图像回答问题，涵盖多种数据）、屏幕导航（解读导航指令并确定目标元素）、屏幕总结（概括屏幕内容）等任务，还包含其他图像和文本数据源，按比例加权混合训练。

- 微调任务与基准：使用多种现有及新发布的基准任务微调，新基准有屏幕标注（评估布局和空间理解）、ScreenQA Short（为问答任务生成新答案格式）、Complex ScreenQA（含难题和不同纵横比屏幕），并介绍了 Multipage DocVQA 和 ChartQA 的处理方法。

### 5.实验与结果

- 实验设置：微调时冻结 ViT 编码器，用 512 的批次大小，文本输入序列长 128，根据任务确定输出序列长，有 OCR 时调整输入长度，模型约 30k 步收敛，主要用 5B 模型实验。

- 结果：在多个任务上超越现有模型，如在 MoTIF、MPDocVQA、WebSRC 等取得新 SOTA，在 ChartQA、DocVQA 等达同类最佳；OCR 作为输入可提升部分问答任务性能，但增加训练负担；模型性能随大小增加而提升，大模型在复杂推理任务上提升更显著。

- 消融研究：pix2struct 补丁在处理横屏图像优势明显，对竖屏图像固定网格略优，综合考虑选择 pix2struct；加入 LLM 生成数据可提高预训练混合效果的综合得分。

### 6.结论：

提出 ScreenAI 模型及统一数据表示，预训练任务有正向迁移效果，数据生成和消融研究验证设计合理，模型性能优异但在部分任务与超大模型有差距，发布数据集促进研究。

