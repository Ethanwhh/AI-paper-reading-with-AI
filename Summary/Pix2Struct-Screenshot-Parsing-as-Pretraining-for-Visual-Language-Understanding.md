# Pix2Struct: Screenshot Parsing as Pretraining for Visual Language Understanding

## 思维导图
![思维导图](/imgs/Pix2Struct-Screenshot-Parsing-as-Pretraining-for-Visual-Language-Understanding.jpg)

## 全文总结
“Pix2Struct: Screenshot Parsing as Pretraining for Visual Language Understanding” 提出了 Pix2Struct，这是一种用于视觉语言理解的预训练图像到文本模型，可在包含视觉语言的任务上进行微调。该模型在四个领域的九个任务中的六个取得了最先进的结果，为视觉语言理解提供了一种通用的方法。

### 1.研究背景与问题

- 视觉语言理解的现状：以往对视觉语言的研究多聚焦于图像和文本可分离的任务，如视觉问答或图像字幕。而视觉情境语言更为普遍，如文档、表格、信息图和用户界面等，其中文本和视觉元素无明显界限。但之前的工作通常依赖于特定领域的方法，缺乏跨领域的数据、模型架构和目标共享，且依赖外部系统会增加工程复杂性和成本。

- 研究目标：提出一种通用的视觉语言理解模型，通过预训练学习从网页截图到简化 HTML 的解析，以解决上述问题，并在多个下游任务中验证其有效性。

### 2.Pix2Struct 方法

- 模型架构：基于 ViT 的图像 - 编码器 - 文本 - 解码器结构。对输入表示进行改进，采用可变分辨率输入，根据给定序列长度提取最大数量的固定尺寸 patches，并使用二维绝对位置嵌入，避免了标准 ViT 缩放输入图像导致的纵横比失真和分辨率限制问题。

- 预训练：通过从网页创建输入图像和目标文本的自监督对进行预训练。收集网页的 HTML 源和 1024x1024 视口的屏幕截图，对 HTML DOM 树进行浓缩，并引入类似 BART 的学习信号，通过掩码 50% 的文本来更好地进行上下文建模。此预训练目标整合了 OCR、语言建模和图像字幕等常见预训练信号。

- 课程学习：在预训练前先进行一个简单的 “热身” 阶段，让模型学习读取文本片段，这有助于提高预训练的稳定性和收敛速度，并提升微调性能。

- 微调：对不同下游任务采用不同的预处理策略。例如，图像字幕任务可直接使用输入图像和输出文本；视觉问答任务将问题直接渲染在原始图像顶部，让模型通过视觉模态同时读取问题和图像；对于 RefExp 任务，则根据候选组件创建训练实例。

### 3.实验设置与结果

- 实验设置：在四个领域（插图、用户界面、自然图像和文档）的多个基准测试上评估 Pix2Struct，使用了不同的数据集，并训练了 282M 参数的 Pix2Struct - Base 和 1.3B 参数的 Pix2Struct - Large 两个模型变体。

- 实验结果：在插图领域的 ChartQA、AI2D、OCR - VQA 任务，用户界面领域的 RefExp、Widget Captioning、Screen2Words 任务，文档领域的 DocVQA、InfographicVQA 任务上，Pix2Struct 均优于之前的方法，在九个任务中的六个取得了最先进的结果。特别是在低资源领域如插图和用户界面，相比特定领域的流水线模型有显著改进。

### 4.分析与讨论

- 消融实验：对预训练组件和可变分辨率输入进行消融实验。结果表明，去除截图解析阶段会大幅降低性能，说明该阶段对学习视觉情境语言至关重要；可变分辨率输入能有效防止纵横比失真并减少填充，有助于更有效的学习。

- 挑战与展望：训练通用视觉语言理解模型面临分辨率敏感、数据筛选和模型通用性等挑战。未来可通过更好的数据筛选和模型扩展进一步提升性能，同时需注意网络有害内容对模型的影响。

### 5.相关工作：
与之前专注于单一领域的工作相比，Pix2Struct 更具通用性。在文档理解领域，与 Donut 和 Dessurt 等模型相关但预训练任务更强大；在 UI 理解领域，相比依赖特定结构的模型，Pix2Struct 仅使用图像输入且可转移；在自然图像理解领域，虽在自然图像任务上不如部分大规模模型，但在其他领域表现更优；在插图领域，优于未充分预训练的模型。此外，还介绍了一些从标记结构学习的相关模型和数据集。
