# Ferret: Refer and Ground Anything Anywhere at Any Granularity

## 思维导图
![思维导图](/imgs/Ferret-Refer-and-Ground-Anything-Anywhere-at-Any-Granularity.jpg)

## 全文总结
“FERRET: REFER AND GROUND ANYTHING ANYWHERE AT ANY GRANULARITY” 由哥伦比亚大学和苹果公司的团队撰写，提出了 Ferret 模型，这是一种新的多模态大语言模型（MLLM），能够理解图像中任何形状或粒度的空间指代，并准确地对开放词汇描述进行定位。
### 1.Ferret 模型概述
- 研究背景：在视觉语言学习中，如何让模型具备空间理解能力是一个基本问题，其中涉及到指代（referring）和定位（grounding）两种能力。现有工作大多分别学习这两种能力，而人类能够在两者之间轻松转换并整合相关能力，受此启发，作者研究如何在一个框架中统一指代和定位，并构建具备相应能力的模型。

- 模型创新点
提出混合区域表示法，结合离散坐标和连续视觉特征来表示图像中的区域，使模型能够处理多种形状的区域输入，如点、框、自由形状等。

构建了 GRIT 数据集，包含丰富的空间知识和多种数据类型，用于模型训练，同时进行空间感知负数据挖掘以增强模型的鲁棒性。

引入 Ferret - Bench，用于评估需要指代 / 定位、语义、知识和推理的任务，展示了模型在多种任务中的优越性能和减少对象幻觉的能力。

### 2.方法
混合区域表示：

为了统一指代不同格式（点、框、自由形状）的区域，提出混合区域表示法。将坐标量化为离散区间，并通过空间感知视觉采样器获取区域的连续视觉特征，最终用坐标和特征共同表示区域。

模型架构：

Ferret 主要由图像编码器、空间感知视觉采样器和大语言模型（LLM）组成。图像经编码器得到嵌入，文本经分词和投影得到嵌入，区域通过特定格式与文本混合输入。空间感知视觉采样器用于处理不规则形状区域，提取其特征。LLM 对图像、文本和区域特征进行联合建模。

### 3.数据集 GRIT

数据类型

层次结构：

根据粒度和任务格式将空间理解分为不同类别，包括个体对象、对象间关系、区域描述和区域复杂推理；任务格式分为 Region - in Text - out、Text - in Region - out 和 Text - Region combined 数据。

来源：

包含从公共数据集转换而来的数据、通过 ChatGPT/GPT - 4 生成的数据以及用于增强模型鲁棒性的负数据。

数据生成与处理
对现有数据集（如 Visual Genome、Object365、RefCOCOs、Flickr30k - Entities 等）进行模板转换，使其变为指令跟随格式。
利用 ChatGPT/GPT - 4 生成对话指令调优数据，强调区域空间知识，包括在场景描述中添加物理关系和区域字幕及坐标，在对话中添加坐标，并用 ChatGPT/GPT - 4 优化生成的对话。
通过图像条件类别定位和语义条件类别定位进行负样本挖掘，增强模型对特定对象类别定位的能力，从而提高模型的鲁棒性。
实验结果
训练细节：初始化图像编码器、LLM 和投影层，在 GRIT 数据集上训练 Ferret 模型，训练时随机选择区域表示方式并去重。
模型性能评估
输入指代能力：在 LVIS 数据集上进行指代对象分类任务，Ferret 在点、框、自由形状指代上均显著优于先前模型。
输出定位能力：在视觉定位任务（如 RefCOCO、RefCOCO+、RefCOCOg 和 Flickr30k Entities 数据集上的实验）和基于定位的图像字幕生成任务（在 Flickr30k Entities 数据集上的实验）中，Ferret 表现出色，达到或接近专业微调方法的性能。
多模态聊天能力：在 Ferret - Bench 测试中，涵盖指代描述、指代推理和对话中的定位任务，Ferret 在所有类型任务中均优于现有模型，如在详细描述类别中将分数从 68.3 提升到 80.9，在新任务中表现卓越。
消融实验：证明了接地和指代数据相互受益，空间感知视觉采样器有效，更大的 LLM 模型尺寸有助于提升性能。
对象幻觉分析：在 POPE 基准测试中，Ferret 与 Shikra 表现相当，远优于其他流行的 MLLM，有效减少了对象幻觉问题。
Ferret 与 GPT - 4V 对比
指代能力：GPT - 4V 通过图像标记或文本坐标两种方式理解指代，在理解小区域时不如 Ferret 精确，但在常识方面更具优势。
定位能力：在交通灯定位示例中，Ferret 在复杂场景中准确识别交通灯的能力优于 GPT - 4V。在一般问答中，GPT - 4V 表现出色，但在需要精确边界框定位的应用中，Ferret 更具优势。
Ferret 模型在多模态理解任务中展现出强大的指代和定位能力，通过创新的方法和数据集，在多个方面取得了显著的性能提升，并在与 GPT - 4V 的对比中显示出独特的优势。
