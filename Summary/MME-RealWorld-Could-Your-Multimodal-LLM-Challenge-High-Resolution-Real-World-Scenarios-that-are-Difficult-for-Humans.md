# MME-RealWorld: Could Your Multimodal LLM Challenge High-Resolution Real-World Scenarios that are Difficult for Humans?

## 思维导图
![思维导图](/imgs/MME-RealWorld-Could-Your-Multimodal-LLM-Challenge-High-Resolution-Real-World-Scenarios-that-are-Difficult-for-Humans.jpg)

## 全文总结

“MME-RealWorld: Could Your Multimodal LLM Challenge High-Resolution Real-World Scenarios that are Difficult for Humans?” 一文针对多模态大语言模型（MLLMs）现有基准测试存在的不足，提出了 MME-RealWorld 基准测试，通过大规模高质量数据收集与标注、严格质量控制，对 29 种 MLLMs 进行评估，深入分析模型在不同任务和领域的表现，为推动 MLLMs 发展提供有力支撑。

### 1.研究背景与动机

- 现有 MLLMs 基准测试存在数据规模小、标注质量受限、任务难度不足等问题，难以衡量模型在现实世界面临的挑战。例如，许多基准测试的问答对数少于 10K，部分虽规模较大但标注由模型生成，且一些基准测试的最高性能已达 80%-90%，难以区分先进模型的优劣。

- 为解决这些问题，需构建一个新的基准测试，关注真实世界场景，具有大规模高质量数据和高难度任务，以准确评估 MLLMs 的能力。

### 2.相关工作

- **多模态基准测试**：介绍了 MME、MMBench、Seed - Bench 等多个现有基准测试，它们在数据规模、任务类型、评估方式等方面各有特点，但普遍存在数据、标注和难度方面的问题。

- **MLLMs**：简述了该领域的发展历程，从基于 BERT 的语言解码器发展到结合 LLMs 的进步，多种模型在不同方面取得进展，但在真实场景中的性能有待检验。

- **高分辨率 MLLMs**：指出提高分辨率对许多任务有效，但现有模型缺乏在严格高分辨率基准测试中的验证。

### 3.MME-RealWorld 基准测试

- **指令与标准**：每个问题手动构建四个选项和一个拒绝回答选项，采用基于规则的过滤器评估模型答案，计算各任务、领域及整体的准确率指标。

- **数据收集与标注**

  - **光学字符识别（OCR）**：从 150,259 张图像中选 3,293 张，由志愿者标注生成 5,740 个感知任务问答对和 500 个推理任务问答对，涵盖多种文本识别和场景理解任务。

  - **遥感（RS）**：从 70,000 多张公共遥感图像中选 1,298 张，由专业人员标注 3,738 个问答对，包括物体计数、颜色识别和空间关系理解任务。

  - **图表（DT）**：从互联网筛选 2,570 张图像，志愿者标注后分为图表和表格感知、推理任务，共 5,933 个问答对，聚焦复杂图表数据挑战。

  - **自动驾驶（AD）**：从 40,000 多张开源数据集图像中选 2,715 张，志愿者标注生成 3,660 个感知任务问答对和 1,334 个推理任务问答对，涉及交通元素识别、意图预测等任务。

  - **监控（MO）**：从 10,000 多张公共数据集图像中选 1,601 张，志愿者标注 2,196 个感知任务问答对和 498 个推理任务问答对，包括物体计数、位置判断和属性识别等任务。

- **MME-RealWorld-CN**：为解决传统中文基准测试的视觉 - 文本不匹配和翻译问题，选择无英文信息的图像和问答对，翻译或收集中文数据，共得到 1,889 张额外图像和 5,917 个问答对。

- **质量控制与分析**：对标注者提出基于图像可回答、提问对象面积限制和交叉检查等要求，确保数据质量。该基准测试数据分辨率高，任务难度大，如最大分辨率达 42,177,408 像素，平均分辨率 3,007,695 像素，基线模型准确率低。

### 4.实验

- **MME-RealWorld 结果**

  - **感知能力**：InternVL-2 感知能力最强，但不同模型在各任务中表现有差异。GPT-4o 在 OCR 任务表现好但在其他任务下降明显，受图像上传限制、保守策略和拒绝回答等因素影响；支持高分辨率输入的模型有优势；不同领域中，专注高分辨率输入的模型在遥感任务表现突出，训练于大量图表数据的模型在图表相关感知任务中能力较强。

  - **推理能力**：Claude 3.5 Sonnet 在推理任务中表现最佳，多数开源模型表现差，顶级模型准确率也未达 45%，表明与人类推理能力差距大。

- **MME-RealWorld-CN 结果**：Qwen2-VL 和 InternVL-2 在中文版感知和推理任务中表现突出，部分模型在中文场景表现有较大差异，如 GPT-4o 等性能下降，基于 Llama3-8B 的模型表现较好。

- **细粒度分析与发现**：多数模型在图像细节感知和动态信息理解方面存在不足，计算效率差异大且缺乏高效处理高分辨率图像的方法，不同模型对不确定问题的回答策略不同，开源模型在指令遵循能力上有待优化。

### 5.研究结论：
MME-RealWorld 是目前最大的纯人工标注且分辨率最高的基准测试，数据质量高、任务实用。对多种模型的评估揭示了性能差距，凸显了模型在复杂图像感知和推理方面的不足，为未来研究指明方向。
